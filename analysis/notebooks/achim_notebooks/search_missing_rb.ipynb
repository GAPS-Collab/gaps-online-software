{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Search for missing RBs in non trace suppressed data with the track trigger\n",
    "\n",
    "* e.g. Run 118 (without trace suppression) is suitable for such a study\n",
    "* Run 120 has central track trigger and trace suppression\n",
    "* Also plot the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gaps_online.tof as gt\n",
    "import gaps_online as go\n",
    "import gaps_tof as gt_cxx\n",
    "import gaps_online.db as db\n",
    "import rust_dataclasses as rd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "#import HErmes.fitting as fit\n",
    "\n",
    "import dashi as d\n",
    "import pylab as p\n",
    "import numpy as np\n",
    "d.visual()\n",
    "import charmingbeauty.visual as vis\n",
    "import charmingbeauty.layout as lo\n",
    "vis.set_style_present()\n",
    "\n",
    "# FIXME add DJANGO_ALLOW_ASYNC_UNSAFE=1 to setup.env\n",
    "RUNPATH  = Path('/data1/nextcloud/cra_data/data/2023_nevis/tof/')\n",
    "CALIPATH = RUNPATH / 'calibration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(data):\n",
    "    return np.sqrt((1/len(data))*((data**2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paddles = db.tof_paddle_manifest()\n",
    "rbs     = db.tdb.models.RB.objects.all()\n",
    "pends   = db.tdb.models.PaddleEnd.objects.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('RB(?P<rbid>[0-9]*)_')\n",
    "\n",
    "calibrations = CALIPATH.glob('*.tof.gaps')\n",
    "calib = dict()\n",
    "\n",
    "for fname in calibrations:\n",
    "    fname = str(fname)\n",
    "    rbid = int(pattern.search(fname).groupdict()['rbid'])\n",
    "    calib[rbid] = go.cxx_api.RBCalibration.from_califile(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (calib[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Run 120 - central track trigger, trace suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "runfiles = (RUNPATH / '120').glob('*.tof.gaps')\n",
    "nfiles = 0\n",
    "events = []\n",
    "for rfile in runfiles:\n",
    "    packets = gt.get_tofpackets(str(rfile), filter=go.cxx_api.PacketType.TofEvent)\n",
    "    events.extend([go.cxx_api.TofEvent.from_tofpacket(k) for k in packets])\n",
    "    nfiles += 1\n",
    "    if nfiles == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_missing_rbs = dict()\n",
    "\n",
    "less_rbs = 0\n",
    "more_rbs = 0\n",
    "for ev in tqdm(events, desc='looking for HG/LG discrepancy...'):\n",
    "    npaddle = ev.mt_event.n_paddles\n",
    "    if len(ev.rbevents) != npaddle:\n",
    "        try:\n",
    "            hits = ev.mt_event.get_dsi_j_ch()\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        for hit in hits:\n",
    "            rbhit = db.get_HG_for_LG(*hit)[0]\n",
    "            if not (rbhit in ev.get_rbids()):\n",
    "                if not (rbhit in all_missing_rbs):\n",
    "                    all_missing_rbs[rbhit] = 0\n",
    "                all_missing_rbs[rbhit] += 1\n",
    "        if npaddle > len(ev.rbevents):\n",
    "            less_rbs += 1\n",
    "        else:\n",
    "            more_rbs += 1\n",
    "print(f'\\n -- less RB {less_rbs/len(events):1.2f} more RB {more_rbs/len(events):1.2f}, events {len(events)}')\n",
    "print (all_missing_rbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len([k for k in all_missing_rbs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get_HG_for_LG(*ev.mt_event.get_dsi_j_ch()[0])\n",
    "#ev.mt_event.get_dsi_j_ch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We saw that the missing RBs are equally distributed across board ids, both for runs with and without trace suppression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Run 118 - no trace suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "runfiles = (RUNPATH / '118').glob('*.tof.gaps')\n",
    "nfiles = 0\n",
    "events = []\n",
    "for rfile in runfiles:\n",
    "    packets = gt.get_tofpackets(str(rfile), filter=go.cxx_api.PacketType.TofEvent)\n",
    "    events.extend([go.cxx_api.TofEvent.from_tofpacket(k) for k in packets])\n",
    "    nfiles += 1\n",
    "    if nfiles == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = events[0]\n",
    "all_rbs = dict()\n",
    "all_ev = len(events)\n",
    "ev_with_missing = 0\n",
    "for rbid in ev.get_rbids(): \n",
    "    all_rbs[rbid] = 0\n",
    "for ev in events:\n",
    "    for rbid in ev.get_rbids():\n",
    "        all_rbs[rbid] += 1\n",
    "    if len(ev.get_rbids()) != 40:\n",
    "        ev_with_missing += 1\n",
    "print (f'-- in total {all_ev} events..')\n",
    "print (f'-- {ev_with_missing/all_ev:1.4f} with at least 1 RB missing')\n",
    "print ('-- RBID --> NEvents(RB) -- -- --')\n",
    "for k in sorted(all_rbs):\n",
    "    print (f'-- {k:02} --> {all_rbs[k]} [{(all_ev - all_rbs[k])/all_ev:1.4f}%]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = dict()\n",
    "for k in rbs:\n",
    "    baselines[k.rb_id] = dict()\n",
    "    for ch in range(0,9):\n",
    "        baselines[k.rb_id][ch] = []\n",
    "        \n",
    "for ev in tqdm(events, desc='Calculating baselines...'):\n",
    "    for rbid in ev.get_rbids():\n",
    "        if rbid == 0:\n",
    "            continue\n",
    "        rbev  = ev.get_rbevent(rbid)\n",
    "        volts = calib[rbid].voltages(rbev)\n",
    "        for ch in rbev.header.get_channels():\n",
    "            bl = volts[ch][10:50].mean()\n",
    "            baselines[rbid][ch].append(bl)\n",
    "\n",
    "for k in baselines:\n",
    "    for ch in baselines[k]:\n",
    "        baselines[k][ch] = np.array(baselines[k][ch])\n",
    "#print (baselines)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rms = dict()\n",
    "all_baseline_rms = []\n",
    "for k in rbs:\n",
    "    baseline_rms[k.rb_id] = dict()\n",
    "    for ch in range(0,8):\n",
    "        baseline_rms[k.rb_id][ch] = rms(baselines[k.rb_id][ch])\n",
    "        all_baseline_rms.append(rms(baselines[k.rb_id][ch]))\n",
    "for k in baseline_rms:\n",
    "    print (f'{k} - {baseline_rms[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rms_bins = np.linspace(0,50,40)\n",
    "rms_bins = 30\n",
    "#print (baseline_rms)\n",
    "fig = p.figure(figsize=lo.FIGSIZE_A4_LANDSCAPE)\n",
    "ax  = fig.gca()\n",
    "ax.set_ylim(bottom=0, top=150)\n",
    "ax.set_xlabel('baseline RMS [mV]', loc='right')\n",
    "ax.set_ylabel('events', loc='top')\n",
    "ax.set_yscale('linear')\n",
    "h = d.histfactory.hist1d(all_baseline_rms,rms_bins)\n",
    "h.line(alpha=0.8,filled=True)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "bl_bins = np.linspace(-3,3,30)\n",
    "figsize = lo.FIGSIZE_A4[0]*10, lo.FIGSIZE_A4[1]*10\n",
    "figsize = lo.FIGSIZE_A4\n",
    "#fig = p.figure(figsize=lo.FIGSIZE_A4_LANDSCAPE)\n",
    "\n",
    "for rbid in tqdm(baselines, desc='Creating distributions...'):\n",
    "    fig, axes = p.subplots(nrows=8,\n",
    "                           ncols=1,\n",
    "                           sharex=True,\n",
    "                           sharey=False,\n",
    "                           figsize=figsize)\n",
    "    axes = axes.flatten(order='F')\n",
    "    idx = 0\n",
    "    for ch in baselines[rbid]:\n",
    "        if ch == 8:\n",
    "            continue\n",
    "        ax = axes[idx]\n",
    "        p.sca(ax)\n",
    "        data = baselines[rbid][ch]\n",
    "        ax.text(-2.9,100,f'RB/CH {rbid}/{ch+1}\\nNEVTS {len(data)}', fontsize=8)\n",
    "        #ax.set_ylim(bottom=0.1)\n",
    "        #ax.set_ylim(bottom=min(data))\n",
    "        ax.set_yscale('symlog')\n",
    "        ax.spines['top'].set_visible(True)\n",
    "        ax.spines['right'].set_visible(True)\n",
    "        h   = d.factory.hist1d(data, bl_bins)\n",
    "        h.line(filled=True, alpha=0.8)\n",
    "        ax.text(0.8,0.05, 'baseline [mV]',transform=p.gcf().transFigure)\n",
    "        ax.text(0.015,0.8, 'nevents',transform=p.gcf().transFigure, rotation=90)\n",
    "        \n",
    "        idx += 1\n",
    "        #pass\n",
    "\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    fig.savefig(f'plots/baselines_rb{rbid}.png')\n",
    "    #break\n",
    "#p.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "data    = baselines[1][1]\n",
    "\n",
    "ax  = fig.gca()\n",
    "ax.set_yscale('symlog')\n",
    "ax.set_xlabel('baseline bin[10:50] [mV]', loc='right')\n",
    "ax.set_ylabel('nevents', loc='top')\n",
    "ax.text(-2.9,max(data)*0.9,'RB/CH 1-1')\n",
    "h   = d.factory.hist1d(data, bl_bins)\n",
    "h.line(filled=True, alpha=0.8)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
