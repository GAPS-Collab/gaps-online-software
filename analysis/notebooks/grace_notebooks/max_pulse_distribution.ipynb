{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gaps_online as go\n",
    "import gaps_online.db as db\n",
    "import re\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load calibrations\n",
    "calib = go.tof.calibrations.load_calibrations(Path('/data1/nextcloud/cra_data/data/2023_nevis/tof/calibration/20240305/'))\n",
    "\n",
    "if len(calib.keys()) != 40: print('Oh no! Some calibrations are missing :(')\n",
    "else: print('Yay! All calibration files were loaded :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing if calib is loaded\n",
    "print(sorted(calib.keys()))\n",
    "print(len(calib.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load paths and populate empty data structures for later use\n",
    "\n",
    "max_pulse_dict = defaultdict(list)\n",
    "max_pulses = []\n",
    "\n",
    "tof_events = []\n",
    "fixed_path = \"/data1/nextcloud/cra_data/data/2023_nevis/tof/138/Run138\"\n",
    "\n",
    "\n",
    "files = glob(f'{fixed_path}_*.tof.gaps')\n",
    "files = files [-5:]\n",
    "print(len(files)) #checking to make sure files was populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#pre-optimization\n",
    "\n",
    "for fname in tqdm(files):\n",
    "    data = go.tof.get_tofpackets(fname, filter=go.cxx_api.PacketType.TofEvent)\n",
    "    evts = [go.cxx_api.TofEvent.from_tofpacket(k) for k in data]\n",
    "\n",
    "    for ev in evts:\n",
    "        rbids = ev.get_rbids()\n",
    "        rbevents = [ev.get_rbevent(k) for k in rbids]\n",
    "\n",
    "        for event_id in rbevents:\n",
    "            if event_id.header.rb_id == 0: continue \n",
    "        \n",
    "            key = event_id.header.rb_id\n",
    "            if len(str(key)) > 2: continue #error where some ids are in the hundreds\n",
    "            try:\n",
    "                calibration = calib[key]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "            voltages = calibration.voltages(event_id)\n",
    "    \n",
    "            for channel in event_id.header.get_channels():\n",
    "                if channel == 8: continue #exclude channel 9\n",
    "                \n",
    "                wv = np.array(voltages[channel]) #calibrating the voltages\n",
    "                max_pulse = np.max(wv) \n",
    "                info = {'rbid' : key, 'channel' : channel, 'max_V' : max_pulse}\n",
    "    \n",
    "                max_pulses.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to optimize for memory\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for fname in tqdm(files):\n",
    "    data = go.tof.get_tofpackets(fname, filter=go.cxx_api.PacketType.TofEvent)\n",
    "    \n",
    "    for ev in (go.cxx_api.TofEvent.from_tofpacket(k) for k in data):\n",
    "        rbids = ev.get_rbids()\n",
    "        \n",
    "        for event_id in (ev.get_rbevent(k) for k in rbids):\n",
    "            if event_id.header.rb_id == 0:\n",
    "                continue\n",
    "            \n",
    "            key = event_id.header.rb_id\n",
    "            if len(str(key)) > 2:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                calibration = calib[key]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            voltages = calibration.voltages(event_id)\n",
    "    \n",
    "            for channel in event_id.header.get_channels():\n",
    "                if channel == 8:\n",
    "                    continue\n",
    "                \n",
    "                wv = np.array(voltages[channel]) #calibrating the voltages\n",
    "                max_pulse = np.max(wv) \n",
    "                info = {'rbid' : key, 'channel' : channel, 'max_V' : max_pulse}\n",
    "    \n",
    "                max_pulses.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying harder to optimize for memory\n",
    "files = files[-200]\n",
    "# Function to chunk the list into smaller sublists\n",
    "def chunk_list(lst, chunk_size):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]\n",
    "\n",
    "# Split files into chunks\n",
    "chunk_size = len(files) // 4\n",
    "file_chunks = chunk_list(files, chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in tqdm(file_chunks):\n",
    "    max_pulses_chunk = []  # Initialize max_pulses for this chunk\n",
    "    for fname in tqdm(chunk):\n",
    "        data = go.tof.get_tofpackets(fname, filter=go.cxx_api.PacketType.TofEvent)\n",
    "        \n",
    "        for ev in (go.cxx_api.TofEvent.from_tofpacket(k) for k in data):\n",
    "            rbids = ev.get_rbids()\n",
    "            \n",
    "            for event_id in (ev.get_rbevent(k) for k in rbids):\n",
    "                if event_id.header.rb_id == 0:\n",
    "                    continue\n",
    "                \n",
    "                key = event_id.header.rb_id\n",
    "                if len(str(key)) > 2:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    calibration = calib[key]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                \n",
    "                voltages = calibration.voltages(event_id)\n",
    "        \n",
    "                for channel in event_id.header.get_channels():\n",
    "                    if channel == 8:\n",
    "                        continue\n",
    "                    \n",
    "                    wv = np.array(voltages[channel]) #calibrating the voltages\n",
    "                    max_pulse = np.max(wv) \n",
    "                    info = {'rbid' : key, 'channel' : channel, 'max_V' : max_pulse}\n",
    "        \n",
    "                    max_pulses_chunk.append(info)  # Append to chunk-specific max_pulses\n",
    "    \n",
    "    max_pulses.extend(max_pulses_chunk)  # Append chunk-specific results to the main max_pulses list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(max_pulses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in tqdm(max_pulses):\n",
    "    r = element['rbid']\n",
    "    channel1 = element['channel']\n",
    "    max_V = element['max_V']\n",
    "\n",
    "    max_pulse_dict[(r, channel1)].append(max_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(max_pulse_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rb, channel in tqdm(sorted(max_pulse_dict.keys())): #individual plots\n",
    "    mp = max_pulse_dict[(rb, channel)]\n",
    "    plt.hist(mp, bins=70)\n",
    "    plt.title(f' RB {rb}, channel {channel+1} max voltage peak frequency')\n",
    "    plt.xlabel('Max Voltage Peak [mV]')\n",
    "    plt.ylabel('count')\n",
    "    #plt.yscale('log')\n",
    "    #plt.xlim(-10, 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#composite plot of most common value from individual plots\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def most_common_integer(lst):\n",
    "    # Use Counter to count occurrences of each integer in the list\n",
    "    counts = Counter(lst)\n",
    "    # Use the most_common() method to get the most common integer\n",
    "    most_common = counts.most_common(1)\n",
    "    # Return the most common integer\n",
    "    return most_common[0][0]\n",
    "    \n",
    "my_dict = {}\n",
    "\n",
    "for (r, channel1), max_pulse_list in max_pulse_dict.items(): #populate dictionary based on the elements of the baseline_rms_dict. baseline_rms_dict uses the library defaultdict to create a list in baselime_rms_dict for each r,channel1 pair\n",
    "    common_max_pulse = most_common_integer(max_pulse_list)   # here the mean is calculated of the baseline_rms_list for each dict containing the list of values for each r,channel1 pair.  \n",
    "    if r in my_dict:\n",
    "        my_dict[r][channel1] = common_max_pulse\n",
    "\n",
    "    else:\n",
    "        my_dict[r]={channel1: common_max_pulse}\n",
    "\n",
    "# Access all the max_pulse_dict values\n",
    "max_pulse_values = [max_V for sub_dict in my_dict.values() for max_V in sub_dict.values()]\n",
    "\n",
    "#filtered_values = np.where(np.array(baseline_rms_values) < 250)[0]\n",
    "\n",
    "# Create a histogram with values\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.hist(np.array(max_pulse_values), histtype = 'step', bins = 24)\n",
    "\n",
    "plt.xlabel('Max Voltage Peak [mV]')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Max Voltage Peak Distribution, Run 138')\n",
    "#plt.xticks(np.arange(0.5, 1.5, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
