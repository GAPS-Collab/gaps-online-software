searchState.loadedDescShard("polars_lazy", 0, "Lazy API of Polars\nDomain specific language for the Lazy API.\nHelper to delay a failing method until the query plan is …\nLazy variant of a DataFrame.\nUtility struct for the <code>when-then-otherwise</code> expression.\nUtility struct for the <code>when-then-otherwise</code> expression.\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nCan be used in a select statement to exclude a column from …\nExplode the aggregated list and just do a hstack instead …\nExpressions that can be used in various contexts. Queries …\nSpecialized expressions for modifying the name of existing …\nMap the group values to the position\nJoin the groups as ‘List&lt;group_dtype&gt;’ to the row …\nSet root name as Alias\nSpecialized expressions for <code>Series</code> of <code>DataType::List</code>.\nTake the nth column in the <code>DataFrame</code>\nExplode the aggregated list and just do a hstack instead …\nExpressions in this node should only be expanding e.g. …\nA wrapper trait for any binary closure …\nA wrapper trait for any closure …\nWrapper type that has special equality properties …\nA ternary operation if true then “foo” else “bar”\nUtility struct for the <code>when-then-otherwise</code> expression.\nRepresents a user-defined function\nUtility struct for the <code>when-then-otherwise</code> expression.\nSee postgres window functions\nGet the group indexes of the group by operation.\nRename Column.\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nReturns whether all values in the column are <code>true</code>.\nCreate a new column with the bitwise-and of the elements …\n“and” operation.\nReturns whether any of the values in the column are <code>true</code>.\nCreate a new column with the bitwise-or of the elements in …\nAppend expressions. This is done by adding the chunks of …\nApply a function/closure over the groups. This should only …\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nApply a function/closure over the groups with many …\nApply a function/closure over the groups of multiple …\nReturn the index of the maximum value of every sublist\nGet the index value that has the maximum value.\nReturn the index of the minimal value of every sublist\nGet the index value that has the minimum value.\nGet the index values that would sort this expression.\nGet the first index of unique values of this expression.\nFind the mean of all the values in the column named <code>name</code>. …\nFill missing value with next non-null.\nGet the <code>binary::BinaryNameSpace</code>\nCompute <code>op(l, r)</code> (or equivalently <code>l op r</code>). <code>l</code> and <code>r</code> must …\nuse a cache of unique, converted dates to apply the …\ncreates a logical expression with a call of the UDF This …\ncreates a logical expression with a call of the UDF This …\nCasts the column given by <code>Expr</code> to a different type.\nCast expression to another data type.\nCompute the cube root of the given expression\nFolds the expressions from left to right keeping the first …\nCreate a Column Expression based on a column name.\nSelect multiple columns by name.\nConcat lists entries.\nCount the values of the Series or Get counts of the group …\nConstruct a column of <code>Datetime</code> from the provided …\nCompute the dot/inner product between two expressions.\nDrop NaN values.\nDrop null values.\nGet the <code>dt::DateLikeNameSpace</code>\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nCompare <code>Expr</code> with other <code>Expr</code> on equality.\nCompare <code>Expr</code> with other <code>Expr</code> on equality where <code>None == None</code>…\nIf polars may parse matches that not contain the whole …\nExclude a column from a wildcard/regex selection.\nExplode the String/List column.\nReplace the floating point <code>NaN</code> values by a value.\nReplace the null values by a value.\nFilter a single column.\nFirst column in DataFrame.\nGet first item of every sublist.\nGet the first value in the group.\nAlias for <code>explode</code>.\nFloor divide <code>self</code> by <code>rhs</code>.\nAccumulate over multiple columns horizontally / row wise.\nFormatting string\nFill missing value with previous non-null.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe function implementation.\nA function that cannot be expressed with <code>map</code> or <code>apply</code> and …\nFunctions\nTake the values by idx.\nGet items in every sublist by index.\nTake the values by a single index.\nCheck if <code>Expr</code> &gt; <code>Expr</code>.\nCheck if <code>Expr</code> &gt;= <code>Expr</code>.\nGet the head of every sublist\nGet the first <code>n</code> elements of the Expr result.\nGroupBy the group to a Series.\nThe function signature.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet mask of finite values if dtype is Float.\nGet mask of infinite values if dtype is Float.\nGet mask of NaN values if dtype is Float.\nGet inverse mask of NaN values if dtype is Float.\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nRun is_not_null operation on <code>Expr</code>.\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nRun is_null operation on <code>Expr</code>.\nJoin all string items in a sublist and place a separator …\nKeep the original root name\nLast column in DataFrame.\nGet last item of every sublist.\nGet the last value in the group.\nReturn the number of rows in the context.\nReturn the number of elements in each list.\nGet the <code>list::ListNameSpace</code>\nCreate a Literal Expression from <code>L</code>. A literal expression …\n“or” operation.\n“or” operation.\nGet minimal value that could be hold by this dtype.\nCheck if <code>Expr</code> &lt; <code>Expr</code>.\nCheck if <code>Expr</code> &lt;= <code>Expr</code>.\nDefine an alias by mapping a function over the original …\nApply a function/closure once the logical plan get …\nApply a closure on the two columns that are evaluated from …\nMap a single dtype.\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nApply a function/closure once the logical plan get …\nApply a function/closure over multiple columns once the …\nMap to a float supertype if numeric, else preserve\nMap to a float supertype.\nMap the dtype to the dtype of the list/array elements.\nMap the dtypes to the “supertype” of a list of lists.\nMap the dtype to the “supertype” of all fields.\nFind the maximum of all the values in the column named <code>name</code>…\nCompute the maximum of the items in every sublist.\nReduce groups to maximum value.\nCreate a new column with the maximum value per row.\nFind the mean of all the values in the column named <code>name</code>. …\nCompute the mean of every sublist and return a <code>Series</code> of …\nReduce groups to the mean value.\nCompute the mean of all values horizontally across columns.\nFind the median of all the values in the column named <code>name</code>…\nReduce groups to the median value.\nFind the minimum of all the values in the column named <code>name</code>…\nCompute the minimum of the items in every sublist.\nReduce groups to minimal value.\nCreate a new column with the minimum value per row.\nGet the number of unique values in the groups.\nGet the <code>name::ExprNameNameSpace</code>\nname\nReduce groups to maximum value.\nReduce groups to minimal value.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality.\nCompare <code>Expr</code> with other <code>Expr</code> on non-equality where …\nConstruct a new <code>DatetimeArgs</code> set to <code>year</code>, <code>month</code>, <code>day</code>\nCreate a new <code>DurationArgs</code> with all fields set to <code>lit(0)</code>. …\nCreate a new UserDefinedFunction\nNegates a boolean column.\nNegate <code>Expr</code>.\nGet the null count of the column/group.\nOptions for the function.\n“or” operation.\nDefine a default for the <code>when-then-otherwise</code> expression.\nDefine a default for the <code>when-then-otherwise</code> expression.\nApply window function over a subgroup. This is similar to …\nRaise expression to the power <code>exponent</code>\nAdd a prefix to the root column name.\nGet the product aggregation of an expression.\nFind a specific quantile of all the values in the column …\nCompute the quantile per group.\nAnalogous to <code>Iterator::reduce</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nThe function output type.\nReverse every sublist\nReverse column\nProxy of the number of rows in both sides of the joins …\nSet this <code>Series</code> as <code>sorted</code> so that downstream code can use …\nShift every sublist.\nShift the values in the array by some period. See the …\nShift the values in the array by some period and fill the …\nShrink numeric columns to the minimal required datatype …\nSlice every sublist.\nSlice the Series. <code>offset</code> may be negative.\nSort every sublist.\nSort with given options.\nSort this column by the ordering of another column …\nCompute the square root of the given expression\nStandard deviation of the values of the Series.\nIf set then polars will return an error if any date …\nCast expression to another data type. Throws an error if …\nAdd a suffix to the root column name.\nSum all the values in the column named <code>name</code>. Shorthand for …\nCompute the sum the items in every sublist.\nReduce groups to the sum of all the values.\nSum all values horizontally across columns.\nGet the tail of every sublist\nGet the last <code>n</code> elements of the Expr result.\nAdd a condition to the <code>when-then-otherwise</code> expression.\nGet a dot language representation of the Expression.\nGet Field result of the expression. The schema is the …\nUpdate the root column name to use lowercase characters.\nMap to a physical type.\nUpdate the root column name to use uppercase characters.\nMap a single dtype with a potentially failing mapper …\nMap all dtypes with a potentially failing mapper function.\nMap a single field with a potentially failing mapper …\nKeep only the unique values in every sublist.\nGet unique values of this expression.\nKeep only the unique values in every sublist.\nGet unique values of this expression, while maintaining …\nGet maximal value that could be hold by this dtype.\nVariance of the values of the Series.\nStart a <code>when-then-otherwise</code> expression.\nAttach a statement to the corresponding condition.\nAdd another condition to the <code>when-then-otherwise</code> …\nSet the day\nSet the days\nSet a dtype.\nSet <code>milliseconds</code>, <code>microseconds</code>, and <code>nanoseconds</code>\nSet <code>hour</code>, <code>minute</code>, and <code>second</code>\nSet <code>hours</code>, <code>minutes</code>, and <code>seconds</code>\nSet the hour\nSet the hours\nSet the microsecond\nSet the microseconds\nSet the milliseconds\nSet the minute\nSet the minutes\nSet the month\nSet the nanoseconds\nField with the same dtype.\nSet the second\nSet the seconds\nSet the weeks\nSet the year\n“xor” operation.\nfunction to apply\nAlso has the input. i.e. avg(“foo”)\nfunction to apply\nfunction arguments\nfunction arguments\nlength is not yet known so we accept negative offsets\noutput dtype of the function\nSpecialized expressions for <code>Series</code> of <code>DataType::String</code>.\nCheck if a binary value contains a literal binary.\nCheck if a binary value ends with the given sequence.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCheck if a binary value starts with the given sequence.\nSpecialized expressions for <code>Series</code> with dates/datetimes.\nChange the underlying <code>TimeUnit</code>. And update the data …\nGet the century of a Date/Datetime\nCombine an existing Date/Datetime with a Time, creating a …\nGet the (local) date of a Date/Datetime.\nGet the (local) datetime of a Datetime.\nGet the month of a Date/Datetime.\nReturns the argument unchanged.\nGet the hour of a Datetime/Time64.\nCalls <code>U::from(self)</code>.\nGet the iso-year of a Date/Datetime. This may not …\nGet the microsecond of a Time64 (scaled from nanosecs).\nGet the millennium of a Date/Datetime\nGet the millisecond of a Time64 (scaled from nanosecs).\nGet the minute of a Datetime/Time64.\nGet the month of a Date/Datetime.\nGet the nanosecond part of a Time64.\nGet the ordinal_day of a Date/Datetime.\nExtract quarter from underlying NaiveDateTime …\nRound the Datetime/Date range into buckets.\nGet the second of a Datetime/Time64.\nConvert from Date/Time/Datetime into String with the given …\nGet the (local) time of a Date/Datetime/Time.\nReturn the timestamp (UNIX epoch) of a Datetime/Date.\nConvert from Date/Time/Datetime into String with the given …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nExpress a Duration in terms of its total number of …\nExpress a Duration in terms of its total number of integer …\nTruncate the Datetime/Date range into buckets.\nExtract the week from the underlying Date representation. …\nExtract the ISO week day from the underlying Date …\nChange the underlying <code>TimeUnit</code> of the <code>Series</code>. This does …\nGet the year of a Date/Datetime\nArguments used by <code>datetime</code> in order to produce an <code>Expr</code> of …\nArguments used by <code>duration</code> in order to produce an <code>Expr</code> of …\nSelects all columns. Shorthand for <code>col(&quot;*&quot;)</code>.\nLike <code>map_binary</code>, but used in a group_by-aggregation …\nFind the mean of all the values in the column named <code>name</code>. …\nCasts the column given by <code>Expr</code> to a different type.\nFolds the expressions from left to right keeping the first …\nCreate a Column Expression based on a column name.\nCollect all <code>LazyFrame</code> computations.\nSelect multiple columns by name.\nConcat multiple <code>LazyFrame</code>s vertically.\nConcat LazyFrames horizontally.\nConcat lists entries.\nConstruct a column of <code>Datetime</code> from the provided …\nSelect multiple columns by dtype.\nSelect multiple columns by dtype.\nConstruct a column of <code>Duration</code> from the provided …\nAccumulate over multiple columns horizontally / row wise.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nA column which is <code>false</code> wherever <code>expr</code> is null, <code>true</code> …\nA column which is <code>true</code> wherever <code>expr</code> is null, <code>false</code> …\nApply a closure on the two columns that are evaluated from …\nFind the maximum of all the values in the column named <code>name</code>…\nFind the mean of all the values in the column named <code>name</code>. …\nFind the median of all the values in the column named <code>name</code>…\nFind the minimum of all the values in the column named <code>name</code>…\nNegates a boolean column.\nFind a specific quantile of all the values in the column …\nAnalogous to <code>Iterator::reduce</code>.\nCreate a column of length <code>n</code> containing <code>n</code> copies of the …\nSum all the values in the column named <code>name</code>. Shorthand for …\nRepresents a user-defined function\nThe function implementation.\nThe function signature.\nname\nOptions for the function.\nThe function output type.\nAllowedOptimizations\nReads LazyFrame from a filesystem or a cloud storage. …\nLazy abstraction over an eager <code>DataFrame</code>. It really is an …\nUtility struct for lazy group_by operation.\nState of the allowed optimizations\nRun every node eagerly. This turns off multi-node …\nGroup by and aggregate.\nAllow parallel table evaluation.\nApply a function over the groups as a new DataFrame.\nCaches the result into a new LazyFrame.\nCancel the query at earliest convenience.\nCast named frame columns, resulting in a new LazyFrame …\nCast all frame columns to the given dtype, resulting in a …\nCloudOptions used to list files.\nCloudOptions used to list files.\nExecute all the lazy operations and collect them into a …\nRecommended concatenation of LazyFrames from many input …\nRecommended concatenation of LazyFrames from many input …\nReturn the number of non-null elements for each column.\nReturn a String describing the optimized logical plan.\nReturn a String describing the optimized logical plan in …\nReturn a String describing the naive (un-optimized) …\nReturn a String describing the naive (un-optimized) …\nRemoves columns from the DataFrame. Note that it’s …\nDrop rows containing None.\nRun every node eagerly. This turns off multi-node …\nRun every node eagerly. This turns off multi-node …\nReturn a String describing the logical plan.\nApply explode operation. See eager explode.\nReplace simple projections with a faster inlined …\nReplace simple projections with a faster inlined …\nFetch the result. If it is ready, a materialized DataFrame …\nFetch is like a collect operation, but it overwrites the …\nAwait the result synchronously.\nCache file reads.\nCache file reads.\nFill NaN values in the DataFrame with an expression.\nFill None values in the DataFrame with an expression.\nFilter by some predicate expression.\nFinish builder\nGet the final LazyFrame.\nGet the final LazyFrame.\nGet the final LazyFrame. This method assumes, that path is …\nGet the first row.\nForce parallel table evaluation.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet current optimizations.\nPerforms a “group-by” on a <code>LazyFrame</code>, producing a …\nSimilar to <code>group_by</code>, but order of the DataFrame is …\nSet whether the CSV file has headers\nReturn first n rows of each group\nSelect the join type.\nInner join this query with another lazy query.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet list of files referenced by this reader.\nGet list of files referenced by this reader.\nGeneric function to join two LazyFrames.\nConsume <code>self</code> and return a <code>JoinBuilder</code> to customize a join …\nJoin on null values. By default null values will never …\nGet the last row.\nLeft join this query with another lazy query.\nThe expressions you want to join the left table on.\nLimit the DataFrame to the first <code>n</code> rows.\nReduce memory usage at the expense of performance\nApply a function/closure once the logical plan get …\nAggregate all the columns as their maximum values.\nAggregate all the columns as their mean values.\nAggregate all the columns as their median values.\nMelt the DataFrame from wide to long format.\nAggregate all the columns as their minimum values.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nTry to stop parsing when <code>n</code> rows are parsed. During …\nCreate the <code>JoinBuilder</code> with the provided <code>LazyFrame</code> as the …\nAggregate all the columns as the sum of their null value …\nThe expressions you want to join both tables on.\nOuter join this query with another lazy query.\nPath of the scanned file. It can be potentially a glob …\nApply predicates/filters as early as possible.\nApply predicates/filters as early as possible.\nProfile a LazyFrame.\nOnly read columns that are used later in the query.\nOnly read columns that are used later in the query.\nAggregate all the columns as their quantile values.\nRaise an error if CSV is empty (otherwise return an empty …\nRechunk the memory to contiguous chunks when parsing is …\nRename columns in the DataFrame.\nReverse the <code>DataFrame</code> from top to bottom.\nThe expressions you want to join the right table on.\nTry to estimate the number of rows so that joins can …\nTry to estimate the number of rows so that joins can …\nAdd a row index column.\nReturn the row index settings.\nGet a handle to the schema — a map from column names to …\nSelect (and optionally rename, with <code>alias</code>) columns from …\nShift the values by a given period and fill the parts that …\nShift the values by a given period and fill the parts that …\nRun many expression optimization rules until fixed point.\nRun many expression optimization rules until fixed point.\nStream a query result into an csv file. This is useful if …\nSlice the DataFrame using an offset (starting row) and a …\nPushdown slices/limits.\nPushdown slices/limits.\nAdd a sort operation to the logical plan.\nAdd a sort operation to the logical plan.\nAggregate all the columns as their standard deviation …\nRun nodes that are capably of doing so on the streaming …\nRun nodes that are capably of doing so on the streaming …\nSuffix to add duplicate column names in join. Defaults to …\nAggregate all the columns as their sum values.\nGet the last <code>n</code> rows.\nReturn last n rows of each group\nTruncate lines that are longer than the schema.\nRun many type coercion optimization rules until fixed …\nRun many type coercion optimization rules until fixed …\nDrop non-unique rows without maintaining the order of kept …\nDrop non-unique rows and maintain the order of kept rows.\nAggregate all the columns as their variance values.\nThe right table in the join.\nCache the DataFrame after reading.\nAdd or replace a column, given as an expression, to a …\nAdd or replace multiple columns, given as expressions, to …\nAdd or replace multiple columns to a DataFrame, but …\nSet the comment prefix for this instance. Lines starting …\nOverwrite the schema with the dtypes in this given Schema. …\nSet  <code>CsvEncoding</code>\nSet the <code>char</code> used as end of line. The default is <code>b&#39;\\n&#39;</code>.\nContinue with next batch when a ParserError is encountered.\nSet the number of rows to use when inferring the csv …\nTreat missing fields as null.\nConfigure the row limit.\nTry to stop parsing when <code>n</code> rows are parsed. During …\nSet values that will be interpreted as missing/ null.\nSet allowed optimizations.\nSet path of the scanned file. Support glob patterns.\nSet paths of the scanned files. Doesn’t glob patterns.\nToggle predicate pushdown optimization.\nToggle projection pushdown optimization.\nSet the <code>char</code> used as quote char. The default is <code>b&#39;&quot;&#39;</code>. If …\nRechunk the memory to contiguous chunks when parsing is …\nRechunk the memory to contiguous chunks when parsing is …\nTry to estimate the number of rows so that joins can …\nConfigure the row index.\nAdd a new column at index 0 that counts the rows.\nAdd a row index column.\nSet the CSV file’s schema\nModify a schema before we run the lazy scanning.\nSet the CSV file’s column separator as a byte character\nToggle expression simplification optimization on or off.\nSkip the first <code>n</code> rows during parsing. The header will be …\nSkip this number of rows after the header location.\nToggle slice pushdown optimization.\nRun nodes that are capably of doing so on the streaming …\nAutomatically try to parse dates/datetimes and time. If …\nToggle type coercion optimization.\nTurn off all optimizations.\nExecutors will evaluate physical expressions and collect …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nTake a DataFrame and evaluate the expressions. Implement …\nWrapper struct that allow us to use a PhysicalExpr in …\nConvert to a partitioned aggregator.\nCan take &amp;dyn Statistics and determine of a file should be …\nTake a DataFrame and evaluate the expression.\nSome expression that are not aggregations can be done per …\nThis is called in partitioned aggregation. Partitioned …\nCalled to merge all the partitioned results in a final …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet the output field of this expr\nA raw binary array\nA binary true or false.\nCache the input at this point in the LP\nIn memory DataFrame\nRemove duplicates from the table\nCatches errors and throws them later\nThis allows expressions to access other tables\nFilter on a boolean mask\nA 32-bit floating point number.\nA 64-bit floating point number.\nGroupby aggregation\nHorizontal concatenation of multiple plans\nAdding columns to the table without a Join\nA 16-bit integer number.\nA 32-bit integer number.\nA 64-bit integer number.\nAn 8-bit integer number.\nJoin operation\nNo unique checks\nCheck if join keys are unique in right dataset.\nA (User Defined) Function\nThe literal Null\nCheck if join keys are unique in left dataset.\nCheck if join keys are unique in both left and right …\nPolars’ <code>select</code> operation, this can mean projection, but …\nSlice the table\nSort the table\nA UTF8 encoded string type.\nAn unsigned 32-bit integer number.\nAn unsigned 64-bit integer number.\nspecify if the scan provider should allow predicate …\nspecify if the scan provider should allow projection …\nspecify if the scan provider should allow slice pushdowns\nArguments\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGetter for the <code>DataType</code> of the value\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLiteral expression.\nCreates a DataFrame from the supplied function &amp; scan …\nfunction to supply the schema. Allows for an optional …")